# Pre-trained Embeddings

| Title | Description |
| ----- | ----------- |
| Persian Wikipedia word2vec<br>[[website]](https://github.com/Text-Mining/Persian-Wikipedia-Corpus/tree/master/models) [[download_cbow]](https://github.com/Text-Mining/Persian-Wikipedia-Corpus/tree/master/models/word2vec-cbow) [[downlad_skipgram]](https://github.com/Text-Mining/Persian-Wikipedia-Corpus/tree/master/models/word2vec-skipgram) | Word2vec models generated using Persian Wikipedia corpus including CBOW and Skipgram models. |
| Persian-Wikipedia-glove<br>[[website]](https://github.com/Text-Mining/Persian-Wikipedia-Corpus/tree/master/models) [[download]](https://github.com/Text-Mining/Persian-Wikipedia-Corpus/tree/master/models/glove) | GloVe model trained on the Persian Wikipedia corpus. |
| Fasttext<br>[[website]](https://fasttext.cc/docs/en/crawl-vectors.html) [[download_bin]](https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.fa.300.bin.gz) [[download_vec]](https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.fa.300.vec.gz) | Pre-trained word vectors for 157 languages, trained on Common Crawl and Wikipedia using fastText. These models were trained using CBOW with position-weights, in dimension 300, with character n-grams of length 5, a window of size 5 and 10 negatives. |
| Word2vec model for Farsi literature<br>[[website]](https://github.com/amnghd/Word2vec-on-Farsi-Literature) [[download]](https://github.com/amnghd/Word2vec-on-Farsi-Literature/archive/master.zip) | This document is dedicated to providing a word2vec model developed for Farsi poems of 48 poets. |
